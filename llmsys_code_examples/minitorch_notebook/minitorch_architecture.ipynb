{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XpkzpoxIG_R",
        "outputId": "91bcb7f4-b796-43fc-8ef7-61155e4a674f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/workspace/11868hw\n",
            "/content/drive/MyDrive/workspace/11868hw/llmsys_code_examples\n",
            "Already up to date.\n",
            "/content/drive/MyDrive/workspace/11868hw/llmsys_code_examples/tensor_demo/miniTorch\n"
          ]
        }
      ],
      "source": [
        "### This script is used to clone the repository to the google drive and setup the directory\n",
        "#from google.colab import drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive_path = '/content/drive'\n",
        "drive.mount(drive_path)\n",
        "workspace_path = os.path.join(drive_path, \"MyDrive/workspace/11868hw\")\n",
        "!mkdir -p {workspace_path}\n",
        "%cd {workspace_path}\n",
        "git_repo_name = \"llmsys_code_examples\"\n",
        "repo_path = os.path.join(workspace_path, git_repo_name)\n",
        "if os.path.isdir(os.path.join(repo_path, \".git\")):\n",
        "  %cd {git_repo_name}\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/llmsystem/llmsys_code_examples.git\n",
        "\n",
        "%cd {repo_path}/tensor_demo/miniTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH9OYx-XJNGQ"
      },
      "source": [
        "## MiniTorch Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X19up_KxJG3y",
        "outputId": "0a7e0e79-6d8f-46d7-889b-2046346b2ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colorama==0.4.3 (from -r requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hypothesis==6.54 (from -r requirements.txt (line 2))\n",
            "  Downloading hypothesis-6.54.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting mypy==0.971 (from -r requirements.txt (line 3))\n",
            "  Downloading mypy-0.971-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting numba==0.58.1 (from -r requirements.txt (line 4))\n",
            "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pre-commit==2.20.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytest==7.1.2 (from -r requirements.txt (line 7))\n",
            "  Downloading pytest-7.1.2-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting pytest-env (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_env-1.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytest-runner==5.2 (from -r requirements.txt (line 9))\n",
            "  Downloading pytest_runner-5.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (4.12.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (25.1.0)\n",
            "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.54->-r requirements.txt (line 2))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from mypy==0.971->-r requirements.txt (line 3))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.1->-r requirements.txt (line 4))\n",
            "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading identify-2.6.6-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 6)) (0.10.2)\n",
            "Collecting virtualenv>=20.0.8 (from pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading virtualenv-20.29.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest==7.1.2->-r requirements.txt (line 7)) (1.5.0)\n",
            "Collecting py>=1.8.2 (from pytest==7.1.2->-r requirements.txt (line 7))\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting tomli>=1.0.0 (from pytest==7.1.2->-r requirements.txt (line 7))\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "INFO: pip is looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-env (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_env-1.1.4-py3-none-any.whl.metadata (5.3 kB)\n",
            "  Downloading pytest_env-1.1.3-py3-none-any.whl.metadata (5.3 kB)\n",
            "  Downloading pytest_env-1.1.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "  Downloading pytest_env-1.1.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "  Downloading pytest_env-1.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "  Downloading pytest_env-1.0.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading pytest_env-1.0.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "INFO: pip is still looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading pytest_env-0.8.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading pytest_env-0.8.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "  Downloading pytest_env-0.8.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "  Downloading pytest_env-0.7.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading pytest-env-0.6.2.tar.gz (1.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 6)) (4.3.6)\n",
            "Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Downloading hypothesis-6.54.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-0.971-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_runner-5.2-py2.py3-none-any.whl (6.8 kB)\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.6-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.29.1-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pytest-env\n",
            "  Building wheel for pytest-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytest-env: filename=pytest_env-0.6.2-py3-none-any.whl size=2346 sha256=fa3b911720becc05d27918ac01f45134050d491bc31f3ad5978a69f0fde38d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/dc/7e/46fabd27efdba96abb8a7ac123c0017a681be4b69c5c2af427\n",
            "Successfully built pytest-env\n",
            "Installing collected packages: sortedcontainers, distlib, virtualenv, tomli, pytest-runner, py, numpy, nodeenv, mypy-extensions, llvmlite, identify, hypothesis, colorama, cfgv, pytest, pre-commit, numba, mypy, pytest-env\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.3.4\n",
            "    Uninstalling pytest-8.3.4:\n",
            "      Successfully uninstalled pytest-8.3.4\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "numba-cuda 0.0.17.1 requires numba>=0.59.1, but you have numba 0.58.1 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.34.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cfgv-3.4.0 colorama-0.4.3 distlib-0.3.9 hypothesis-6.54.0 identify-2.6.6 llvmlite-0.41.1 mypy-0.971 mypy-extensions-1.0.0 nodeenv-1.9.1 numba-0.58.1 numpy-1.23.5 pre-commit-2.20.0 py-1.11.0 pytest-7.1.2 pytest-env-0.6.2 pytest-runner-5.2 sortedcontainers-2.4.0 tomli-2.2.1 virtualenv-20.29.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "eb7ed02e4b8c40249fc6fa8f6638d0ce"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KB5PVywaJgpS",
        "outputId": "0e2bf6fa-09d5-4b8d-f0e3-5185157c7a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==2.4.0 (from -r requirements.extra.txt (line 1))\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting embeddings==0.0.8 (from -r requirements.extra.txt (line 2))\n",
            "  Downloading embeddings-0.0.8-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting networkx==2.4 (from -r requirements.extra.txt (line 3))\n",
            "  Downloading networkx-2.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting plotly==4.14.3 (from -r requirements.extra.txt (line 4))\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydot==1.4.1 (from -r requirements.extra.txt (line 5))\n",
            "  Downloading pydot-1.4.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting python-mnist (from -r requirements.extra.txt (line 6))\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting streamlit==1.12.0 (from -r requirements.extra.txt (line 7))\n",
            "  Downloading streamlit-1.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting streamlit-ace (from -r requirements.extra.txt (line 8))\n",
            "  Downloading streamlit_ace-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.extra.txt (line 9)) (2.5.1+cu124)\n",
            "Collecting watchdog==1.0.2 (from -r requirements.extra.txt (line 10))\n",
            "  Downloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (17.0.0)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 1)) (24.2)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from networkx==2.4->-r requirements.extra.txt (line 3)) (4.4.2)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.14.3->-r requirements.extra.txt (line 4))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from pydot==1.4.1->-r requirements.extra.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (1.9.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.5.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (8.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (8.6.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (11.1.0)\n",
            "Collecting protobuf<4,>=3.12 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting pydeck>=0.1.dev5 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pympler>=0.9 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (13.9.4)\n",
            "Collecting semver (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (6.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.2)\n",
            "Collecting validators>=0.2 (from streamlit==1.12.0->-r requirements.extra.txt (line 7))\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.1.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (3.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.extra.txt (line 9))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.extra.txt (line 9)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.extra.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (1.24.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 1)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (4.0.12)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.21.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.extra.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2.18.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 1))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 7)) (0.1.2)\n",
            "Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading streamlit_ace-0.1.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-mnist, xxhash, watchdog, validators, semver, retrying, pympler, pydot, protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, dill, responses, pydeck, plotly, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, embeddings, nvidia-cusolver-cu12, datasets, streamlit, streamlit-ace\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.4\n",
            "    Uninstalling pydot-3.0.4:\n",
            "      Successfully uninstalled pydot-3.0.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.25.1 requires networkx>=3.0, but you have networkx 2.4 which is incompatible.\n",
            "scikit-image 0.25.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.34.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "nx-cugraph-cu12 24.12.0 requires networkx>=3.2, but you have networkx 2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 embeddings-0.0.8 multiprocess-0.70.13 networkx-2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 plotly-4.14.3 protobuf-3.20.3 pydeck-0.9.1 pydot-1.4.1 pympler-1.1 python-mnist-0.7 responses-0.18.0 retrying-1.3.4 semver-3.0.4 streamlit-1.12.0 streamlit-ace-0.1.1 validators-0.34.0 watchdog-1.0.2 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "884085ed41444c54a70d97e86576d1d7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.extra.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIF9pXvKKLPF",
        "outputId": "64087e9d-830d-4b59-a11d-29375e4ab0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/drive/MyDrive/workspace/11868hw/llmsys_code_examples/tensor_demo/miniTorch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: minitorch\n",
            "  Running setup.py develop for minitorch\n",
            "Successfully installed minitorch-0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -Ue ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "15_DC_j_KVWI"
      },
      "outputs": [],
      "source": [
        "import minitorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0inD-mEqKwgv"
      },
      "source": [
        "## Go Through Minitorch\n",
        "\n",
        "This is a high level abstraction of some basic components in MiniTorch.\n",
        "\n",
        "<img src=\"./imgs/high_level_abstraction.png\"></img>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vmds3l9Kwgv"
      },
      "source": [
        "`class Parameter` is a very important component defined in `class Module`. What the models are learing is actually these `Parameter`(s). Optimizers also look for these parameters and update them following the weight updating rules. See `minitorch/module.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ics4O5_Kwgw"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict, Optional, Sequence, Tuple\n",
        "\n",
        "class Parameter:\n",
        "    \"\"\"\n",
        "    A Parameter is a special container stored in a `Module`.\n",
        "\n",
        "    It is designed to hold a `Variable`, but we allow it to hold\n",
        "    any value for testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x: Any, name: Optional[str] = None) -> None:\n",
        "        self.value = x\n",
        "        self.name = name\n",
        "        if hasattr(x, \"requires_grad_\"):\n",
        "            self.value.requires_grad_(True)\n",
        "            if self.name:\n",
        "                self.value.name = self.name\n",
        "\n",
        "    def update(self, x: Any) -> None:\n",
        "        \"Update the parameter value.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4WS47_bfKwgw"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Modules form a tree that store parameters and other\n",
        "    submodules. They make up the basis of neural network stacks.\n",
        "\n",
        "    Attributes:\n",
        "        _modules : Storage of the child modules\n",
        "        _parameters : Storage of the module's parameters\n",
        "        training : Whether the module is in training mode or evaluation mode\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    _modules: Dict[str, 'Module']\n",
        "    _parameters: Dict[str, Parameter]\n",
        "    training: bool\n",
        "\n",
        "    def parameters(self) -> Sequence[Parameter]:\n",
        "        \"Enumerate over all the parameters of this module and its descendents.\"\n",
        "        return [j for _, j in self.named_parameters()]\n",
        "\n",
        "    def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
        "        return self.forward(*args, **kwargs)\n",
        "\n",
        "    def train(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `train`.\"\n",
        "        for m in self.modules():\n",
        "            m.train()\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self) -> None:\n",
        "        \"Set the mode of this module and all descendent modules to `eval`.\"\n",
        "        for m in self.modules():\n",
        "            m.eval()\n",
        "        self.training = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-F0cQT5Kwgx"
      },
      "source": [
        "We define a `RParam` function here to initialize the `Parameter` in `project/run_sentiment.py`. We can define more functions for initialization i.e. [xavier](https://paperswithcode.com/method/xavier-initialization), [kaiming](https://paperswithcode.com/method/he-initialization) and structure them better inside the minitorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8aJUrMzJKwgx"
      },
      "outputs": [],
      "source": [
        "# Initialization\n",
        "def RParam(*shape):\n",
        "    r = 0.1 * (minitorch.rand(shape, backend=BACKEND) - 0.5)\n",
        "    return minitorch.Parameter(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXU-yNXHKwgx"
      },
      "source": [
        "See `minitorch/optim.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5WWvsBvlKwgx"
      },
      "outputs": [],
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, parameters: Sequence[Parameter]):\n",
        "        self.parameters = parameters\n",
        "\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def __init__(self, parameters: Sequence[Parameter], lr: float = 1.0):\n",
        "        super().__init__(parameters)\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self) -> None:\n",
        "        for p in self.parameters:\n",
        "            if p.value is None:\n",
        "                continue\n",
        "            elif hasattr(p.value, \"grad\"):\n",
        "                if p.value.grad is not None:\n",
        "                    p.update(p.value - self.lr * p.value.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY_2R1vpKwgy"
      },
      "source": [
        "`class Function` is an abstraction for operators with `forward` and `backward` functions. It represents the kind of computation we perform at each node. See `minitorch/tensor_functions.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dml5S37PKwgy"
      },
      "outputs": [],
      "source": [
        "from minitorch.autodiff import Context\n",
        "from minitorch.tensor import Tensor\n",
        "\n",
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "\n",
        "        # Create a new variable from the result with a new history.\n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2qSIpDNBKwgy"
      },
      "outputs": [],
      "source": [
        "class Add(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, t1: Tensor, t2: Tensor) -> Tensor:\n",
        "        return t1.f.add_zip(t1, t2)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        return grad_output, grad_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnzUZd37Kwgz"
      },
      "source": [
        "`class Tensor` is the basic data structure that handles multidimensioanl arrays. See `minitorch/tensor.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lwcsCJiCKwgz"
      },
      "outputs": [],
      "source": [
        "from minitorch.tensor_ops import TensorBackend\n",
        "from minitorch.tensor import History\n",
        "from minitorch.tensor_data import TensorData\n",
        "\n",
        "class Tensor:\n",
        "    \"\"\"\n",
        "    Tensor is a generalization of Scalar in that it is a Variable that\n",
        "    handles multidimensional arrays.\n",
        "    \"\"\"\n",
        "\n",
        "    backend: TensorBackend\n",
        "    history: Optional[History]\n",
        "    grad: Optional[Tensor]\n",
        "    _tensor: TensorData\n",
        "    unique_id: int\n",
        "    name: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE8y70cPKwgz"
      },
      "source": [
        "## Data Storage and Operators\n",
        "\n",
        "This diagram shows several important components of `class Tensor`, including data storage `class TensorData`, backend `class TensorBackend`, etc. Backend relies on `class TensorOps` to execute the actual computation for different operators. Basic functions are implemented and abstracted by `class Function`.\n",
        "\n",
        "<img src=\"./imgs/data_storage_operators.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0ij11O6_Kwgz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from typing import Sequence\n",
        "from typing_extensions import TypeAlias\n",
        "\n",
        "Storage: TypeAlias = npt.NDArray[np.float64]\n",
        "OutIndex: TypeAlias = npt.NDArray[np.int32]\n",
        "Index: TypeAlias = npt.NDArray[np.int32]\n",
        "Shape: TypeAlias = npt.NDArray[np.int32]\n",
        "Strides: TypeAlias = npt.NDArray[np.int32]\n",
        "\n",
        "UserIndex: TypeAlias = Sequence[int]\n",
        "UserShape: TypeAlias = Sequence[int]\n",
        "UserStrides: TypeAlias = Sequence[int]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D6AUI-1zKwg0"
      },
      "outputs": [],
      "source": [
        "class TensorData:\n",
        "    _storage: Storage\n",
        "    _strides: Strides\n",
        "    _shape: Shape\n",
        "    strides: UserStrides\n",
        "    shape: UserShape\n",
        "    dims: int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOTAukDCKwg0"
      },
      "source": [
        "### Indexing\n",
        "\n",
        "<img src=\"./imgs/strides.png\"></img>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ARtLPu2wKwg1"
      },
      "outputs": [],
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHzKqmt7Kwg1",
        "outputId": "b801f608-d7ac-4eb7-c8b8-0de5f0256e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "x.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aflSF5cKwg1",
        "outputId": "d282fec6-3bae-4001-f59d-82cff44b33dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6,), (1,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x._tensor.shape, x._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scBtjPIrKwg1",
        "outputId": "4904b673-14d9-483b-8040-0393debbbdce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[1.000000 2.000000 3.000000]\n",
              "\t[4.000000 5.000000 6.000000]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y = minitorch.Tensor.make(\n",
        "    storage=x._tensor._storage,\n",
        "    shape=(2, 3),\n",
        "    strides=(3, 1),\n",
        "    backend=x.backend)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kj3abEVKwg1",
        "outputId": "22b1a0b3-2fe6-466d-933f-fb672df51898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3., 4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTGvDG10p_g",
        "outputId": "6d10eed0-e258-4fec-c574-7eddf557bce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 3), (3, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "y._tensor.shape, y._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQEVHr4sKwg1",
        "outputId": "e4b3835f-f3b7-4e66-ff15-e3add2e9468f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "y._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Ui7WoAKwg2",
        "outputId": "59d82805-bdad-4856-f7a9-e9a271551487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000]\n",
              "\t\t[2.000000]]\n",
              "\t[\n",
              "\t\t[3.000000]\n",
              "\t\t[4.000000]]\n",
              "\t[\n",
              "\t\t[5.000000]\n",
              "\t\t[6.000000]]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "z = x.view(3, 2, 1)\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En14LQscKwg2",
        "outputId": "da88f068-3865-48a0-ce9f-e108fdb4ff05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3, 2, 1), (2, 1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "z._tensor.shape, z._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4M4-YgfKwg2",
        "outputId": "903d341b-239b-4852-d7b1-6506cea50762"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "z._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AR9aKBFKwg2",
        "outputId": "5adddc3d-2523-405e-d8be-028f4bc947ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 3, 4.0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "z_index = [1, 1, 0]\n",
        "pos = minitorch.index_to_position(z_index, z._tensor._strides)\n",
        "z[tuple(z_index)] == z._tensor._storage[pos], pos, z[tuple(z_index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljP7gomHKwg2",
        "outputId": "ef3ae28e-29c8-425e-bd49-31a583ac4357"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "out_index = [0, 0, 0]\n",
        "minitorch.to_index(3, z.shape, out_index)\n",
        "out_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UhJoSReKwg2",
        "outputId": "0ec2a753-846a-42f1-cd91-e2c0caffa5a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "shape = (2, 3)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1NGGsctKwg3",
        "outputId": "cd1c6625-5903-4432-92e9-5838ac8f0443"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "shape = (3, 2, 1)\n",
        "minitorch.strides_from_shape(shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bCK6ZOVKwg3",
        "outputId": "5c60ccb1-252d-47e5-cf98-99e5c83285b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[1.000000 3.000000 5.000000]\n",
              "\t\t[2.000000 4.000000 6.000000]]]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "p = z.permute(2, 1, 0)\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTYuZRGIKwg3",
        "outputId": "978ba110-c9e2-4f74-fd26-9a5f292c036b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 2, 3), (1, 1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "p._tensor.shape, p._tensor.strides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q28eHbRWKwg3",
        "outputId": "e9070544-09d8-4912-af23-45cc6afe1a84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "p._tensor._storage is x._tensor._storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UTlXzH2Kwg3",
        "outputId": "94e8e783-a796-436b-b788-590d932948a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "p_index = [0, 0, 0]\n",
        "minitorch.to_index(-1, p.shape, p_index)\n",
        "p_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2uQrsMLKwg3",
        "outputId": "fa6640cc-833d-49be-f672-53240a4c0089"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "minitorch.index_to_position(p_index, p._tensor._strides)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipScE_ULKwg4"
      },
      "source": [
        "### Backend & Operators\n",
        "\n",
        "See `minitorch/tensor_ops.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7QuP88fTKwg4"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Generic, Iterable, Tuple, TypeVar\n",
        "from minitorch.tensor_ops import MapProto\n",
        "\n",
        "class TensorOps:\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        raise NotImplementedError(\"Not implemented in this assignment\")\n",
        "\n",
        "    @staticmethod\n",
        "    def cmap(fn: Callable[[float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        pass\n",
        "    cuda = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Es03tJIBKwg4"
      },
      "outputs": [],
      "source": [
        "from minitorch.tensor import operators\n",
        "from typing import Type\n",
        "\n",
        "class TensorBackend:\n",
        "    def __init__(self, ops: Type[TensorOps]):\n",
        "        # Maps\n",
        "        self.neg_map = ops.map(operators.neg)\n",
        "        self.sigmoid_map = ops.map(operators.sigmoid)\n",
        "        self.relu_map = ops.map(operators.relu)\n",
        "        self.log_map = ops.map(operators.log)\n",
        "        self.exp_map = ops.map(operators.exp)\n",
        "        self.id_map = ops.map(operators.id)\n",
        "        self.id_cmap = ops.cmap(operators.id)\n",
        "        self.inv_map = ops.map(operators.inv)\n",
        "\n",
        "        # Zips\n",
        "        self.add_zip = ops.zip(operators.add)\n",
        "        self.mul_zip = ops.zip(operators.mul)\n",
        "        self.lt_zip = ops.zip(operators.lt)\n",
        "        self.eq_zip = ops.zip(operators.eq)\n",
        "        self.is_close_zip = ops.zip(operators.is_close)\n",
        "        self.relu_back_zip = ops.zip(operators.relu_back)\n",
        "        self.log_back_zip = ops.zip(operators.log_back)\n",
        "        self.inv_back_zip = ops.zip(operators.inv_back)\n",
        "\n",
        "        # Reduce\n",
        "        self.add_reduce = ops.reduce(operators.add, 0.0)\n",
        "        self.mul_reduce = ops.reduce(operators.mul, 1.0)\n",
        "\n",
        "        # Matrix Multiply\n",
        "        self.matrix_multiply = ops.matrix_multiply\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "F0KSoDe2Kwg4"
      },
      "outputs": [],
      "source": [
        "class CudaKernelOps(TensorOps):\n",
        "    @staticmethod\n",
        "    def map(fn: Callable[[float], float]) -> MapProto:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def zip(fn: Callable[[float, float], float]) -> Callable[[Tensor, Tensor], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce(\n",
        "        fn: Callable[[float, float], float], start: float = 0.0\n",
        "    ) -> Callable[[Tensor, int], Tensor]:\n",
        "        ### Your Implementation ###\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def matrix_multiply(a: Tensor, b: Tensor) -> Tensor:\n",
        "        ### Your Implementation ###\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uO7xsynCKwg4"
      },
      "outputs": [],
      "source": [
        "# In project/run_sentiment.py\n",
        "backend_name = \"CudaKernelOps\"\n",
        "\n",
        "if backend_name == \"CudaKernelOps\":\n",
        "    #from minitorch.cuda_kernel_ops import CudaKernelOps\n",
        "    BACKEND = minitorch.TensorBackend(CudaKernelOps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqzdsHDKwg4"
      },
      "source": [
        "### Connect to CUDA Kernels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_lbjGHW4cDl",
        "outputId": "6a215d0c-593e-42fa-aae7-f5758905a5a9"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2025.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
            "Downloading pytools-2025.1.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp311-cp311-linux_x86_64.whl size=660362 sha256=1328ab5c10437cabc800b3c34d93cc91ae72f3df2d1ff69d9b5001a96c2e537f\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/66/50/c65e6116d7e0e16abe0f7c19b50327f76724ccfefbdc61a1b9\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.9 pycuda-2024.1.2 pytools-2025.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "jPMj418zKwg4"
      },
      "outputs": [],
      "source": [
        "import ctypes\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "import pycuda.autoinit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "nh7-UUUSKwg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2a54b3-1906-4229-81ee-f241fd72eba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda kernels not implemented: combine.so not found\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    lib = ctypes.CDLL(\"minitorch/cuda_kernels/combine.so\")\n",
        "except:\n",
        "    print(\"cuda kernels not implemented: combine.so not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside cuda_kernel_ops.py, we call cuda kernels"
      ],
      "metadata": {
        "id": "knSho53n4ltO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "b5wShSAxKwg5"
      },
      "outputs": [],
      "source": [
        "def map(fn: Callable[[float], float]) -> MapProto:\n",
        "    \"See `tensor_ops.py`\"\n",
        "    fn_id = fn_map[fn]\n",
        "\n",
        "    def ret(a: Tensor, out: Optional[Tensor] = None) -> Tensor:\n",
        "        if out is None:\n",
        "            out = a.zeros(a.shape)\n",
        "\n",
        "        # Define the argument type for the tensorMap function\n",
        "        lib.tensorMap.argtypes = [\n",
        "            ctypes.POINTER(ctypes.c_double),  # out\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # out_strides\n",
        "            ctypes.c_int,                    # out_size\n",
        "            ctypes.POINTER(ctypes.c_double),  # in_storage\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_shape\n",
        "            ctypes.POINTER(ctypes.c_int),    # in_strides\n",
        "            ctypes.c_int,                    # shape_len\n",
        "            ctypes.c_int,                    # fn_id\n",
        "        ]\n",
        "\n",
        "        # Define the return type for the tensorMap function\n",
        "        lib.tensorMap.restype = None\n",
        "\n",
        "        # Convert the numpy arrays to gpuarrays that can be loaded to the gpu\n",
        "        out_array_gpu = gpuarray.to_gpu(out._tensor._storage)\n",
        "        out_shape_gpu = gpuarray.to_gpu(out._tensor._shape.astype(np.int32))\n",
        "        out_strides_gpu = gpuarray.to_gpu(out._tensor._strides.astype(np.int32))\n",
        "        in_array_gpu = gpuarray.to_gpu(a._tensor._storage)\n",
        "        in_shape_gpu = gpuarray.to_gpu(a._tensor._shape.astype(np.int32))\n",
        "        in_strides_gpu = gpuarray.to_gpu(a._tensor._strides.astype(np.int32))\n",
        "\n",
        "\n",
        "        # Call the function\n",
        "        lib.tensorMap(\n",
        "            ctypes.cast(out_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(out_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(out_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(out.size),\n",
        "            ctypes.cast(in_array_gpu.ptr, ctypes.POINTER(ctypes.c_double)),\n",
        "            ctypes.cast(in_shape_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.cast(in_strides_gpu.ptr, ctypes.POINTER(ctypes.c_int)),\n",
        "            ctypes.c_int(len(a.shape)),\n",
        "            ctypes.c_int(fn_id)\n",
        "        )\n",
        "\n",
        "        # Copy the gpuarray back to the cpu\n",
        "        out._tensor._storage = out_array_gpu.get()\n",
        "\n",
        "        # Free the gpuarrays\n",
        "        out_array_gpu.gpudata.free()\n",
        "        out_shape_gpu.gpudata.free()\n",
        "        out_strides_gpu.gpudata.free()\n",
        "        in_array_gpu.gpudata.free()\n",
        "        in_shape_gpu.gpudata.free()\n",
        "        in_strides_gpu.gpudata.free()\n",
        "        return out\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU4Ahx1nKwg5"
      },
      "source": [
        "```c++\n",
        "    void tensorMap(\n",
        "        scalar_t* out,\n",
        "        int* out_shape,\n",
        "        int* out_strides,\n",
        "        int out_size,\n",
        "        scalar_t* in_storage,\n",
        "        int* in_shape,\n",
        "        int* in_strides,\n",
        "        int shape_size,\n",
        "        int fn_id\n",
        "    ) {\n",
        "        int threadsPerBlock = BASE_THREAD_NUM;\n",
        "        int blocksPerGrid = (out_size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "        mapKernel<<<blocksPerGrid, threadsPerBlock>>>(out, out_shape, out_strides, out_size, in_storage, in_shape, in_strides, shape_size, fn_id);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIi_tfGMbyn"
      },
      "source": [
        "## **MiniTorch Automatic Differentiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ObLD2XlOMa-k"
      },
      "outputs": [],
      "source": [
        "from minitorch import SimpleBackend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcLYzqnRMjQ1"
      },
      "source": [
        "MiniTorch tensors are connect operations in the computational graph as described in last lecture.\n",
        "\n",
        "Note: this example uses SimpleBackend implemented in Python, which isn't nearly as good as your Cuda backend :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyC8EG7DM2Rp"
      },
      "source": [
        "Let's consider a simple example of $z = x * y$, the element-wise multiplication of two 1-d tensors.\n",
        "\n",
        "Suppose this happened somewhere in your Neural Network.\n",
        "\n",
        "During your backward pass, you've calculated your loss **$\\frac{\\partial loss}{\\partial z}$.**\n",
        "\n",
        "You want **$\\frac{\\partial loss}{\\partial x}$** and **$\\frac{\\partial loss}{\\partial y}$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Xs5afN5MMpzO"
      },
      "outputs": [],
      "source": [
        "x = minitorch.tensor([1, 2, 3, 4, 5, 6], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Hw4_uu78Mrd7"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v0nxjHkMsZE",
        "outputId": "bd87c649-cab9-4ffa-b3f2-6bc2f22ce1ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "KsxiG6qZMuLP"
      },
      "outputs": [],
      "source": [
        "y = minitorch.tensor([2, 4, 6, 8, 10, 12], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "SLN44ySMMwhv"
      },
      "outputs": [],
      "source": [
        "y.requires_grad_(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGcml7r7MxYJ",
        "outputId": "245e7ecd-c17c-46e3-88b0-ae026398a0d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MmGykxaHMyPK"
      },
      "outputs": [],
      "source": [
        "z = x * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64Qc8cpqMzHU",
        "outputId": "bb8b2d1c-2453-4239-e609-c96fb4418365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 8.000000 18.000000 32.000000 50.000000 72.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDFHOyK-Nwnv"
      },
      "source": [
        "**How does MiniTorch calculate the gradients for each tensor?**\n",
        "\n",
        "By using *reverse mode automatic differentiation* - let's examine how this is implemented in MiniTorch with the simple example above of\n",
        "\n",
        "`z = x * y`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htY91cdMNz-P"
      },
      "source": [
        "They contain important fields and methods for enabling automatic differentiation, including the\n",
        "* `self.f` field - tells us what backend we're using\n",
        "* `self.history` field - tracks the computation\n",
        "* `self.grad` field - stores the gradient for the optimizer\n",
        "* `chain_rule` method - lets us obtain partial adjoints for `backpropagate` to propagate from a node to its inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RATsGxgN1z9"
      },
      "source": [
        "We are going to utilize the computation graph as a way to automatically compute derivatives of arbitrary python functions.\n",
        "\n",
        "The trick behind this autodifferentiation is to implement the derivative of each individual function, and then utilize the chain rule to compute a derivative for any scale value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRd7dFTiN4vO"
      },
      "source": [
        "**Let's examine the trace of the forward evaluation**\n",
        "to get a better idea of how `z` got computed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvduw9OZN8Mz"
      },
      "source": [
        "1. Open `minitorch/tensor.py:153` to find `__mul__`\n",
        "\n",
        "\n",
        "```python\n",
        "def __mul__(self, b: TensorLike) -> Tensor:\n",
        "        return Mul.apply(self, self._ensure_tensor(b))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2oOIbMjN9cP"
      },
      "source": [
        "2. Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCVoaPFLN__y"
      },
      "source": [
        "3. Open `minitorch/tensor_functions.py:33` to find\n",
        "\n",
        "```python\n",
        "class Function:\n",
        "    @classmethod\n",
        "    def _backward(cls, ctx: Context, grad_out: Tensor) -> Tuple[Tensor, ...]:\n",
        "        return wrap_tuple(cls.backward(ctx, grad_out))  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def _forward(cls, ctx: Context, *inps: Tensor) -> Tensor:\n",
        "        return cls.forward(ctx, *inps)  # type: ignore\n",
        "\n",
        "    @classmethod\n",
        "    def apply(cls, *vals: Tensor) -> Tensor:\n",
        "        raw_vals = []\n",
        "        need_grad = False\n",
        "        for v in vals:\n",
        "            if v.requires_grad():\n",
        "                need_grad = True\n",
        "            raw_vals.append(v.detach())\n",
        "\n",
        "        # Create the context.\n",
        "        ctx = Context(not need_grad)\n",
        "\n",
        "        # Call forward with the variables.\n",
        "        c = cls._forward(ctx, *raw_vals)\n",
        "        \n",
        "        back = None\n",
        "        if need_grad:\n",
        "            back = minitorch.History(cls, ctx, vals)\n",
        "        return minitorch.Tensor(c._tensor, back, backend=c.backend)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caVkjSbrODs_"
      },
      "source": [
        "\n",
        "So, we can see that Z is a new tensor with a **history**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfBZ7PMOGC5"
      },
      "source": [
        "### **How do we get $\\frac{\\partial l}{\\partial x}$ and $\\frac{\\partial l}{\\partial y}$ given $\\frac{\\partial l}{\\partial z}$?**\n",
        "\n",
        "\n",
        "You've probably written this code in pytorch\n",
        "```python\n",
        "loss.sum().backward()\n",
        "```\n",
        "\n",
        "Since `loss.sum()` is still a tensor, you're calling the following method\n",
        "\n",
        "```python\n",
        "    def backward(self, grad_output: Optional[Tensor] = None) -> None:\n",
        "        if grad_output is None:\n",
        "            assert self.shape == (1,), \"Must provide grad_output if non-scalar\"\n",
        "            grad_output = Tensor.make([1.0], (1,), backend=self.backend)\n",
        "        backpropagate(self, grad_output)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S78EcRTuOJl2"
      },
      "source": [
        "\n",
        "You've reached a point in the graph you've constructed for the backward pass where you have the following gradient propagated back to $z$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "3XADUxquOJ0k"
      },
      "outputs": [],
      "source": [
        "dldz = minitorch.tensor([1, 1, 1, 1, 1, 1], backend=SimpleBackend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNoqEQkjONVq"
      },
      "source": [
        "Let's make use of `z.history`, which tells us:\n",
        "1. The function used to calculate z\n",
        "2. The context ie. intermediate values we need to calculate the gradients of z's inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z54eaYtOL2s",
        "outputId": "03078540-e30c-4b5e-db30-64ee92f89caa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History(last_fn=<class 'minitorch.tensor_functions.Mul'>, ctx=Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000])), inputs=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "z.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr-cq8FNOQyy"
      },
      "source": [
        "In your `backpropagate` function, you should use the `chain_rule` method of a tensor in `minitorch/tensor.py:373`.\n",
        "\n",
        "```python\n",
        "    def chain_rule(self, d_output: Any) -> Iterable[Tuple[Variable, Any]]:\n",
        "        h = self.history\n",
        "        assert h is not None\n",
        "        assert h.last_fn is not None\n",
        "        assert h.ctx is not None\n",
        "\n",
        "        x = h.last_fn._backward(h.ctx, d_output)\n",
        "        assert len(x) == len(h.inputs), f\"Bug in function {h.last_fn}\"\n",
        "        return [\n",
        "            (inp, inp.expand(self._ensure_tensor(d_in)))\n",
        "            for inp, d_in in zip(h.inputs, x)\n",
        "        ]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiqjO9zdOPRi",
        "outputId": "af71ef05-2452-4bb4-d7bf-257ccbcb9e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "minitorch.tensor_functions.Mul"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "z.history.last_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdPAjWIsOSaR",
        "outputId": "0bcdf13a-371f-4d80-cafe-d4e4b6f37fdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Context(no_grad=False, saved_values=(\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000], \n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# saved_values == (x, y)\n",
        "z.history.ctx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aatjEeJxOYAX"
      },
      "source": [
        "If $z = x*y$ then $\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zk1ink0Owjy"
      },
      "source": [
        "\n",
        "Open `minitorch/tensor_functions.py:99` to find\n",
        "```python\n",
        "class Mul(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx: Context, a: Tensor, b: Tensor) -> Tensor:\n",
        "        ctx.save_for_backward(a, b)\n",
        "        return a.f.mul_zip(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx: Context, grad_output: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        a, b = ctx.saved_values\n",
        "        return (\n",
        "            grad_output.f.mul_zip(b, grad_output),\n",
        "            grad_output.f.mul_zip(a, grad_output),\n",
        "        )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "53FFiHhqOTXt"
      },
      "outputs": [],
      "source": [
        "# This is exactly what's happening in backward!\n",
        "dldx, dldy = z.history.last_fn._backward(z.history.ctx, dldz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sUs5ZZiOdyR"
      },
      "source": [
        "$\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial z} \\frac{\\partial z}{\\partial x} = \\frac{\\partial l}{\\partial z} y$\n",
        "```python\n",
        "dldx = tensor([1,1,1,1,1,1]) * tensor([2,4,6,8,10,12])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7emxjBhSOUkt",
        "outputId": "5863f70c-6d0f-40a9-852b-15959bc31cbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[2.000000 4.000000 6.000000 8.000000 10.000000 12.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "dldx # = dldz * y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlpUEUqiOgXu",
        "outputId": "cf35755b-78f1-4b17-fe47-669b1a42171e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "(dldz * y) == dldx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vmnIzUOhV1",
        "outputId": "fc8bc5c3-d2c1-4424-e255-e2bba6b1c8d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 2.000000 3.000000 4.000000 5.000000 6.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "dldy # = dldz * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvD4ddzIOiD9",
        "outputId": "1a3ef660-8cb6-40d3-aaa0-503e472f627e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.000000 1.000000 1.000000 1.000000 1.000000 1.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "(dldz * x) == dldy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86o3hrUwOlT9"
      },
      "source": [
        "Defining functions in this way (Tensor in, Tensor out) is really powerful because it enables us to easily calculate the gradient of any python function that operates on Tensors eg. .sum(), .permute(), etc.\n",
        "\n",
        "There are many things to be careful of when shapes change eg.\n",
        "How do you calculate the gradient when you've done a `.sum(dim=2)`?\n",
        "\n",
        "Backpropagation vs. Reverse Mode Automatic Differentiation\n",
        "1. Modern deep learning frameworks don't use backpropagation on the forward computational graph.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IYJbDGLrIK93",
        "gH9OYx-XJNGQ",
        "mWRAVR1kQSFS",
        "QE0eesQ04d-W",
        "xSo94QvzCFbn",
        "7sejR8-MTPmM",
        "RdCXpyn3j9e-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}